# ğŸ§  LLM-Powered Domain Chat Assistant

This is a Streamlit-based chat assistant that answers user questions using a custom knowledge base from PDFs, datasets, and OCR-extracted text. It supports domain-specific prompting, FAISS-based retrieval, and optional audio transcription using OpenAI Whisper.

## ğŸš€ Features

- ğŸ“„ Upload any PDF and chat with its content
- ğŸ©º Built-in medical dataset support
- ğŸ–¼ï¸ OCR support for image and camera-captured text
- ğŸ™ï¸ Voice input using Whisper (via audio file upload)
- ğŸ” FAISS-based semantic search over embedded chunks
- ğŸ§  Prompt templates for generic, medical, and legal domains
- ğŸ›ï¸ Model selector: flan-t5, gpt2, and more
- ğŸŒ Streamlit-based frontend

## ğŸ—‚ Folder Structure

```
llm-chat-assistant/
â”œâ”€â”€ app.py                  # Main Streamlit app
â”œâ”€â”€ query.py                # Core RAG logic (FAISS + prompting)
â”œâ”€â”€ ingest_dynamic.py       # PDF ingestion
â”œâ”€â”€ process_dataset.py      # Dataset loader
â”œâ”€â”€ transcribe_audio.py     # Whisper-based audio transcription
â”œâ”€â”€ faiss_index/            # Stores index.pkl and chunks.pkl
â”œâ”€â”€ data/                   # For uploaded PDFs
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ“¦ Setup

```bash
# Clone the repo
git clone https://github.com/yourusername/llm-chat-assistant.git
cd llm-chat-assistant

# Create a virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Run the app
streamlit run app.py
```

## â˜ï¸ Deploy on Streamlit

- Push your project to GitHub
- Go to https://streamlit.io/cloud
- Choose your repo and set `app.py` as the entry point
- Done!

## ğŸ§  Future Ideas

- Live camera feed for OCR
- Text-to-speech output
- Auto-indexing for multiple PDFs
- More domains & better prompt tuning

---

Created with â¤ï¸ by Vineetha